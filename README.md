Ниже готовый **README на русском** с учётом добавленной модели **CatBoostClassifier** и подбора порога под максимальный precision. Клади как `README.md` в корень репозитория.

---

# Удовлетворённость пассажиров авиалиний — Logistic Regression и CatBoost

Небольшой, воспроизводимый baseline-проект по бинарной классификации удовлетворённости пассажиров на табличных данных.
Проект демонстрирует аккуратную предобработку, интерпретируемый baseline на `LogisticRegression` и сильную табличную модель `CatBoostClassifier` с выбором рабочего порога под **precision**.

## Датасет

Публичный табличный датасет об удовлетворённости пассажиров авиакомпании (наподобие распространённого набора на ML-платформах).
Целевая переменная: `satisfaction` (binary). Признаки — числовые и категориальные (категориальные кодируются One-Hot для Logistic Regression; CatBoost может работать как с OHE, так и с исходными категориальными признаками).

## Структура проекта

```
.
├─ Flight_satisfaction.ipynb
├─ data.csv    
├─ requirements.txt
└─ README.md
```

## Подход

* Разбиение на train/test с фиксированным `random_state` для воспроизводимости.
* Предобработка через `sklearn`: `StandardScaler` для числовых, One-Hot Encoding для категориальных.
* Модели:

  * `LogisticRegression` как интерпретируемый baseline.
  * `CatBoostClassifier` как сильная модель для табличных данных.
* Оценка на тестовой выборке: Accuracy, Precision, Recall, F1, ROC-AUC, PR-AUC.
* Отрисовка confusion matrix.
* Подбор порога классификации по **максимальному precision** (с опциональным ограничением на минимальный recall).

## Результаты (test set)

В ноутбуке выводятся сводные метрики для всех моделей. Для базовой Logistic Regression на текущем разбиении получено ориентировочно:

| Метрика   | Значение |
| --------- | -------- |
| Accuracy  | 0.88     |
| Precision | 0.86     |
| Recall    | 0.87     |
| F1-score  | 0.86     |

`CatBoostClassifier` обычно превосходит baseline по  метрикам. Итоговые числа зависят от конкретного разбиения и набора признаков; смотрите таблицу метрик и графики в ноутбуке.

> Порог 0.5 не обязателен. В ноутбуке показан подбор порога, максимизирующего **precision** (при необходимости с ограничением на минимум **recall**), чтобы снизить долю ложноположительных в чувствительных сценариях.

## Быстрый старт

### 1) Окружение

```bash
python -m venv .venv
source .venv/bin/activate  # Windows: .venv\Scripts\activate
pip install -r requirements.txt
```

### 2) Запуск ноутбука

Откройте `Flight_satisfaction.ipynb` и выполните все ячейки.

* Укажите путь к CSV в первом блоке загрузки данных.
* В конце ноутбука выводятся метрики, таблицы и confusion matrix.

## Воспроизводимость

* Рекомендуется Python 3.10+.
* Зависимости: `numpy`, `pandas`, `scikit-learn`, `matplotlib`, `catboost` (см. `requirements.txt`).
* Фиксируйте `random_state` в разбиении и моделях, чтобы получать стабильные результаты.

## Интерпретация и заметки

* Logistic Regression обеспечивает прозрачный baseline и первичную диагностику признаков.
* CatBoost лучше улавливает нелинейности и взаимодействия в табличных данных, что отражается ростом метрик.
* Для задач с дорогими ложноположительными предсказаниями используйте подбор порога под **precision** и анализируйте PR-кривую.


---
