# Удовлетворённость пассажиров авиалиний — базовый baseline на логистической регрессии

Небольшой, воспроизводимый baseline-проект по бинарной классификации удовлетворённости пассажиров на табличных данных. 
Фокус — прозрачность и простота: аккуратный `sklearn`-pipeline для предобработки и одна интерпретируемая модель Logistic Regression.

## Датасет
Публичный табличный датасет об удовлетворённости пассажиров авиакомпании (наподобие популярного набора с ML-платформ).  
Целевая переменная: `satisfaction` (binary). Признаки — числовые и категориальные (категориальные кодируются One-Hot).

> Если вы клонируете репозиторий без исходных данных, поместите CSV в `data/raw/` и укажите путь к файлу в первом блоке ноутбука.

## Структура проекта
```
.
├─ Flight_satisfaction.ipynb
├data.csv    
├─ requirements.txt
└─ README.md
```

## Подход
- Разбиение на train/test с фиксированным `random_state` для воспроизводимости.
- Предобработка через `sklearn`-конвейеры: `StandardScaler` для числовых, One-Hot Encoding для категориальных.
- Модель: `LogisticRegression` c регуляризацией по умолчанию; гиперпараметры могут подбираться через GridSearchCV/Optuna.
- Оценка на отложенной тестовой выборке стандартными метриками классификации.

## Результаты (test set)
| Метрика    | Значение |
|------------|----------|
| Accuracy   | 0.88     |
| Precision  | 0.86     |
| Recall     | 0.87     |
| F1-score   | 0.86     |

> Метрики получены на текущем разбиении в ноутбуке. При пересоздании сплита возможны небольшие отклонения (± несколько сотых).

## Быстрый старт

### 1) Окружение
```bash
python -m venv .venv
source .venv/bin/activate  # Windows: .venv\Scripts\activate
pip install -r requirements.txt
```

### 2) Запуск ноутбука
Откройте `notebooks/Flight_satisfaction.ipynb` и выполните все ячейки.
- Укажите путь к CSV в первом блоке загрузки данных.
- В конце ноутбука выводятся метрики, соответствующие таблице выше.

### 3) (Опционально) Сохранение артефактов
Раскомментируйте строки с `joblib.dump`, чтобы сохранить обученный pipeline в `models/`.  
Графики (ROC/PR-кривые, confusion matrix) можно сохранять в `reports/`.

## Воспроизводимость
- Рекомендуется Python 3.10+.
- Зависимости: `numpy`, `pandas`, `scikit-learn`, `matplotlib` (см. `requirements.txt`).
- Фиксируйте `random_state` в разбиении и модели, чтобы получать стабильные результаты.

## Что улучшить дальше
1. **Добавить ROC-AUC и PR-AUC** и сохранить соответствующие кривые.  
2. **Подобрать порог классификации** под целевые бизнес-метрики (max F1, max Recall при фиксированном Precision и т. п.).  
3. **Калибровка вероятностей** (`CalibratedClassifierCV`) и отчёт о калиброванности.  
4. **Подбор гиперпараметров** для `C`, `penalty`, `solver` с кросс-валидацией; добавить разброс метрик.  
5. **Сравнение с бэйзлайном** от `DummyClassifier` для оценки «прироста над шансом».  
6. **Экспорт артефактов**: сохранять обученный конвейер (`joblib`) и добавить простой **CLI** `predict.py` для пакетного скоринга CSV.  
7. **Model Card**: источник данных, область применения, ограничения и возможные вопросы fairness.  
8. **CI**: линтер, форматтер, элементарные unit-тесты на препроцессинг и GitHub Actions.

## Лицензия
MIT (при необходимости замените на предпочитаемую).
